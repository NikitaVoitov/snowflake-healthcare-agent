# Healthcare Contact Center ReAct Agent

An AI-powered healthcare contact center assistant built with **ReAct (Reasoning + Acting)** pattern using LangGraph on Snowflake SPCS.

---

## Executive Summary

### The Challenge

Contact centers are critical for healthcare payers, handling thousands of member inquiries daily. Agents need rapid access to:

- **Structured data**: Claims history, coverage details, member demographics
- **Unstructured knowledge**: Policies, FAQs, procedures, call transcripts
- **Audio context**: Transcribed call recordings for follow-up conversations

Traditional systems require agents to navigate multiple applications, causing delays and inconsistent service.

### The Solution

This lab builds a **production-ready AI assistant** using the **ReAct loop pattern**:

- **Native tool calling** via `langchain-snowflake` ChatSnowflake (claude-3-5-sonnet)
- **Intelligent tool selection** - automatic tool binding with `llm.bind_tools()`
- **Semantic model** for NLâ†’SQL via `SnowflakeCortexAnalyst` REST API
- **Parallel search** via `SnowflakeCortexSearchRetriever` REST API across FAQs, Policies, and Transcripts
- **Conversation memory** persisted via Snowflake checkpointer
- **Fully async** orchestration via LangGraph with `asyncio.TaskGroup`

All within Snowflake's secure environment using official `langchain-snowflake` integration.

---

## Architecture

### ReAct Workflow

```mermaid
flowchart TB
 subgraph snowsight["Snowsight"]
        StreamlitApp["Native Streamlit App"]
        ServiceFunction["HEALTHCARE_AGENT_QUERY Function"]
  end
 subgraph react_graph["LangGraph ReAct Workflow"]
        ModelNode["ChatSnowflake + Tools"]
        Router{"route_after_model"}
        ToolNode["Execute tools"]
        FinalAnswer["Generate response"]
  end
 subgraph spcs["SPCS Container"]
        FastAPI["FastAPI + uvicorn"]
        ReactService["ReActAgentService"]
        react_graph
        Checkpointer["SnowflakeSaver<br>Conversation Memory"]
  end
 subgraph langchain["langchain-snowflake"]
        ChatSnowflake["ChatSnowflake<br>claude-3-5-sonnet"]
        CortexAnalyst["SnowflakeCortexAnalyst<br>NLâ†’SQL"]
        CortexRetriever["SnowflakeCortexSearchRetriever<br>REST API"]
  end
 subgraph cortex["Cortex Services"]
        CortexREST["Cortex REST API<br>/api/v2/cortex/inference:complete"]
        AnalystREST["Cortex Analyst REST API<br>/api/v2/cortex/analyst/message"]
        CortexSearch["SnowflakeCortexSearchRetriever<br>REST API"]
  end
 subgraph db["HEALTHCARE_DB"]
        SemanticModel["Semantic Model YAML"]
        MemberData["CALL_CENTER_MEMBER_DENORMALIZED"]
        KnowledgeData["FAQs / Policies / Transcripts"]
  end
    StreamlitApp -- <br> --> ServiceFunction
    ServiceFunction --> FastAPI
    FastAPI --> ReactService
    ReactService --> react_graph
    ModelNode --> Router & ChatSnowflake
    Router -- <br> --> ToolNode & FinalAnswer
    ToolNode -- loop --> ModelNode
    FinalAnswer --> Checkpointer
    ChatSnowflake --> CortexREST
    ToolNode -- <br> --> CortexAnalyst & CortexRetriever
    CortexRetriever --> CortexSearch
    CortexAnalyst --> AnalystREST
    AnalystREST --> SemanticModel & MemberData
    CortexSearch --> KnowledgeData
```

### LangGraph 

![langgraph_dev](https://github.com/user-attachments/assets/e5ca09f4-8387-45a0-be69-b592447e75a3)

### ReAct Loop Example

```
User Query: "What claims does member 786924904 have, and what's the policy on appeals?"

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ITERATION 1                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Thought: User wants claims for a specific member AND policy info.    â”‚
â”‚          I should query member data first.                           â”‚
â”‚                                                                      â”‚
â”‚ Action: query_member_data                                            â”‚
â”‚ Action Input: {"query": "claims for member 786924904"}               â”‚
â”‚                                                                      â”‚
â”‚ Observation: Found 4 claims:                                         â”‚
â”‚   - Office Visit: $150 (approved)                                    â”‚
â”‚   - Lab Work: $275 (pending)                                         â”‚
â”‚   - Specialist: $450 (approved)                                      â”‚
â”‚   - Emergency: $1,200 (in review)                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ITERATION 2                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Thought: Now I have the claims. User also asked about appeal policy.â”‚
â”‚          I should search the knowledge base.                         â”‚
â”‚                                                                      â”‚
â”‚ Action: search_knowledge                                             â”‚
â”‚ Action Input: {"query": "claim appeal policy procedure"}             â”‚
â”‚                                                                      â”‚
â”‚ Observation: Found in FAQs:                                          â”‚
â”‚   "Appeals must be filed within 30 days of denial.                   â”‚
â”‚    Submit Form CA-101 with supporting documentation..."              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ITERATION 3                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Thought: I have both the claims data and appeal policy info.        â”‚
â”‚          I can now provide a complete answer.                        â”‚
â”‚                                                                      â”‚
â”‚ Action: FINAL_ANSWER                                                 â”‚
â”‚ Answer: "Member 786924904 has 4 claims on file:                      â”‚
â”‚          â€¢ Office Visit ($150) - Approved                            â”‚
â”‚          â€¢ Lab Work ($275) - Pending                                 â”‚
â”‚          â€¢ Specialist ($450) - Approved                              â”‚
â”‚          â€¢ Emergency ($1,200) - In Review                            â”‚
â”‚                                                                      â”‚
â”‚          Regarding appeals: You have 30 days from denial to file.    â”‚
â”‚          Use Form CA-101 with supporting documentation..."           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Database Schema

```
HEALTHCARE_DB
â”œâ”€â”€ MEMBER_SCHEMA
â”‚   â”œâ”€â”€ MEMBERS (member_id, dob, name, plan_id, status, address, phone) - 242 rows
â”‚   â”œâ”€â”€ CLAIMS (claim_id, member_id, claim_date, service_type, amount, status) - 632 rows
â”‚   â”œâ”€â”€ COVERAGE (plan_id, plan_name, deductible, copay_office, copay_er)
â”‚   â””â”€â”€ CALL_CENTER_MEMBER_DENORMALIZED (denormalized view for Cortex Analyst) - 632 rows
â”‚
â”œâ”€â”€ KNOWLEDGE_SCHEMA
â”‚   â”œâ”€â”€ FAQS (faq_id, question, answer, category) - 4 rows
â”‚   â”œâ”€â”€ POLICIES (policy_id, policy_name, content, version)
â”‚   â”œâ”€â”€ CALL_TRANSCRIPTS (transcript_id, member_id, transcript_text, summary) - 32 rows
â”‚   â””â”€â”€ AUDIO_FILES (audio_id, call_recording_path, duration)
â”‚
â”œâ”€â”€ CHECKPOINT_SCHEMA (LangGraph State Persistence)
â”‚   â”œâ”€â”€ LANGGRAPH_CHECKPOINTS
â”‚   â”œâ”€â”€ LANGGRAPH_CHECKPOINT_BLOBS
â”‚   â”œâ”€â”€ LANGGRAPH_CHECKPOINT_WRITES
â”‚   â””â”€â”€ LANGGRAPH_CHECKPOINT_MIGRATIONS
â”‚
â”œâ”€â”€ STAGING
â”‚   â”œâ”€â”€ SEMANTIC_MODELS (Cortex Analyst semantic model YAML)
â”‚   â”œâ”€â”€ HEALTHCARE_IMAGES (Docker image repository)
â”‚   â””â”€â”€ RAW_DATA (CSVs, PDFs)
â”‚
â””â”€â”€ Cortex Search Services
    â”œâ”€â”€ FAQS_SEARCH (on answer column)
    â”œâ”€â”€ POLICIES_SEARCH (on content column)
    â””â”€â”€ TRANSCRIPTS_SEARCH (on transcript_text column)
```

---

## Project Structure

```
healthcare/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py                          # FastAPI app with lifespan
â”‚   â”œâ”€â”€ config.py                        # pydantic-settings with SPCS detection
â”‚   â”œâ”€â”€ dependencies.py                  # @lru_cache + Depends factories
â”‚   â”œâ”€â”€ exceptions.py                    # Custom exceptions
â”‚   â”œâ”€â”€ otel_setup.py                    # OpenTelemetry initialization
â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â””â”€â”€ agent_routes.py              # /query, /stream, /sf-query endpoints
â”‚   â”œâ”€â”€ graphs/
â”‚   â”‚   â”œâ”€â”€ react_state.py               # HealthcareReActState TypedDict
â”‚   â”‚   â”œâ”€â”€ react_workflow.py            # ReAct reasoning loop graph
â”‚   â”‚   â””â”€â”€ react_prompts.py             # System prompts + tool descriptions
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ base.py                      # BaseSchema with camelCase config
â”‚   â”‚   â”œâ”€â”€ requests.py                  # QueryRequest (member_id validation)
â”‚   â”‚   â”œâ”€â”€ responses.py                 # AgentResponse, StreamEvent
â”‚   â”‚   â””â”€â”€ agent_types.py               # AnalystResultModel, SearchResultModel
â”‚   â”œâ”€â”€ tools/
â”‚   â”‚   â””â”€â”€ healthcare_tools.py          # @tool decorated functions
â”‚   â”œâ”€â”€ middleware/
â”‚   â”‚   â”œâ”€â”€ healthcare_prompts.py        # Dynamic prompt middleware
â”‚   â”‚   â””â”€â”€ logging.py                   # Request logging middleware
â”‚   â””â”€â”€ services/
â”‚       â”œâ”€â”€ react_agent_service.py       # AgentService.execute(), .stream()
â”‚       â”œâ”€â”€ llm_service.py               # ChatSnowflake factory
â”‚       â”œâ”€â”€ analyst_service.py           # SnowflakeCortexAnalyst factory
â”‚       â”œâ”€â”€ search_service.py            # SnowflakeCortexSearchRetriever factory
â”‚       â”œâ”€â”€ cortex_tools.py              # AsyncCortexAnalystTool, AsyncCortexSearchTool
â”‚       â”œâ”€â”€ checkpointer.py              # LangGraph checkpointer factory
â”‚       â”œâ”€â”€ snowflake_checkpointer.py    # CustomAsyncSnowflakeSaver implementation
â”‚       â””â”€â”€ snowflake_session.py         # SPCS OAuth + resilient session wrapper
â”‚
â”œâ”€â”€ patches/                                 # langchain-snowflake bug fixes
â”‚   â”œâ”€â”€ langchain_snowflake_auth_patched.py          # OAuth token authenticator
â”‚   â”œâ”€â”€ langchain_snowflake_base_patched.py          # disable_streaming parameter
â”‚   â”œâ”€â”€ langchain_snowflake_connection_base_patched.py # Connection handling
â”‚   â”œâ”€â”€ langchain_snowflake_mcp_integration_patched.py # MCP integration
â”‚   â”œâ”€â”€ langchain_snowflake_rest_client_patched.py   # SNOWFLAKE_HOST fix
â”‚   â”œâ”€â”€ langchain_snowflake_retrievers_patched.py    # Retriever fixes
â”‚   â”œâ”€â”€ langchain_snowflake_streaming_patched.py     # ToolCallChunk for streaming
â”‚   â”œâ”€â”€ langchain_snowflake_tools_patched.py         # Message format + tool name
â”‚   â”œâ”€â”€ langchain_snowflake_utils_patched.py         # Response metadata for OTel
â”‚   â”œâ”€â”€ apply_patches.sh                             # Apply patches to .venv
â”‚   â”œâ”€â”€ revert_patches.sh                            # Revert patches
â”‚   â””â”€â”€ README.md                                    # Patch documentation
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ sql/
â”‚   â”‚   â”œâ”€â”€ 01_setup_db.sql              # Database, schemas, tables
â”‚   â”‚   â”œâ”€â”€ 02_checkpoint_schema.sql     # LangGraph checkpoint tables
â”‚   â”‚   â”œâ”€â”€ 03_load_data.sql             # Data loading
â”‚   â”‚   â”œâ”€â”€ 04_cortex_services.sql       # Cortex Search services
â”‚   â”‚   â”œâ”€â”€ 05_compute_resources.sql     # Compute pool, warehouse
â”‚   â”‚   â”œâ”€â”€ 08_spcs_deploy.sql           # SPCS deployment
â”‚   â”‚   â”œâ”€â”€ 09_semantic_model.sql        # Semantic model stage/upload
â”‚   â”‚   â””â”€â”€ semantic_models/
â”‚   â”‚       â””â”€â”€ healthcare_semantic_model.yaml
â”‚
â”œâ”€â”€ streamlit/                           # Streamlit Container Runtime app
â”‚   â”œâ”€â”€ app.py                           # SSE streaming + service function fallback
â”‚   â”œâ”€â”€ environment.yml                  # Warehouse Runtime dependencies
â”‚   â””â”€â”€ pyproject.toml                   # Container Runtime dependencies
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ conftest.py                      # ReAct-specific fixtures
â”‚   â”œâ”€â”€ unit/
â”‚   â”‚   â”œâ”€â”€ test_models.py
â”‚   â”‚   â””â”€â”€ test_snowflake_checkpointer.py
â”‚   â””â”€â”€ integration/
â”‚       â”œâ”€â”€ test_agent_service.py
â”‚       â””â”€â”€ test_real_snowflake.py
â”‚
â”œâ”€â”€ pyproject.toml                       # Dependencies (Python 3.11)
â”œâ”€â”€ langgraph.json                       # LangGraph config
â”œâ”€â”€ Dockerfile                           # Distroless multi-stage build
â””â”€â”€ README.md
```

---

## Features

| Feature | Description |
|---------|-------------|
| **Native Tool Calling** | `ChatSnowflake.bind_tools()` with automatic schema generation |
| **Langchain-snowflake** | Full integration with official Snowflake LangChain library |
| **Semantic Model** | NLâ†’SQL via `SnowflakeCortexAnalyst` with verified queries |
| **Parallel Search** | `asyncio.TaskGroup` searches FAQs, Policies, Transcripts simultaneously |
| **Conversation Memory** | History persisted via Snowflake checkpointer for multi-turn context |
| **SPCS OAuth + Auto-Refresh** | Automatic token refresh via `token_file_path` when SPCS OAuth tokens expire |
| **Token-Level Streaming** | Real-time LLM output + tool call progress via SSE |
| **Container Runtime** | Streamlit app runs on SPCS compute pool with internal DNS access |
| **OpenTelemetry Observability** | GenAI tracing with LangChain instrumentation |

---

## OpenTelemetry Observability

This project includes **OpenTelemetry instrumentation** for LangChain/LangGraph applications using standard GenAI semantic conventions.

### Telemetry Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Healthcare Agent (LangGraph)                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  LangChainInstrumentor (auto-instrumentation)                        â”‚
â”‚  â”œâ”€â”€ Traces: workflow â†’ step â†’ LLM/tool spans                       â”‚
â”‚  â””â”€â”€ GenAI attributes: model, tokens, tool calls                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚ OTLP (HTTP :4318 GRPC :4317)
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OpenTelemetry Collector                                              â”‚
â”‚  â””â”€â”€ Exporters: Splunk Observability Cloud / Jaeger / etc.          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### GenAI Span Attributes

The instrumentation captures rich telemetry following [OpenTelemetry GenAI Semantic Conventions](https://opentelemetry.io/docs/specs/semconv/gen-ai/):

| Attribute | Description | Example |
|-----------|-------------|---------|
| `gen_ai.request.model` | LLM model name | `claude-3-5-sonnet` |
| `gen_ai.response.model` | Response model | `claude-3-5-sonnet` |
| `gen_ai.provider.name` | LLM provider | `snowflake` |
| `gen_ai.tool.name` | Tool function name | `search_knowledge` |
| `gen_ai.tool.call.id` | Unique tool call ID | `tooluse_cJ0D_A...` |

### Trace Hierarchy

```
workflow react_healthcare (trace root)
â”œâ”€â”€ step model
â”‚   â””â”€â”€ LLM claude-3-5-sonnet
â”œâ”€â”€ step tools
â”‚   â””â”€â”€ tool search_knowledge
â””â”€â”€ step model
    â””â”€â”€ LLM claude-3-5-sonnet
```

### Setup

1. **Configure environment**:
   ```env
   OTEL_SERVICE_NAME=healthcare-agent
   OTEL_EXPORTER_OTLP_ENDPOINT=http://your-collector:4318
   OTEL_TRACES_EXPORTER=otlp
   ```

2. **OTel is auto-initialized** via `src/otel_setup.py` on application startup.

---

## Streamlit UI

![stremlit_app_ui](https://github.com/user-attachments/assets/0dc71a12-c8e9-4cd1-92ae-5a6925ae33e2)

### Streaming Mode

The Streamlit app supports **real-time SSE streaming** when running on Container Runtime:

- **Enable streaming progress** toggle shows live tool execution status
- Real-time events: `ğŸ¤” Thinking...` â†’ `ğŸ“Š Calling tool` â†’ `ğŸ“¥ Results` â†’ `âœ… Answer`
- Full `analystResults` and `searchResults` returned in streaming mode
- Fallback to synchronous service function if streaming unavailable

### Container Runtime vs Warehouse Runtime

| Feature | Container Runtime | Warehouse Runtime |
|---------|------------------|-------------------|
| **Compute** | SPCS Compute Pool | Virtual Warehouse |
| **Network** | Internal DNS access | External only |
| **Streaming** | SSE via `/agents/stream` | Service function only |
| **Dependencies** | `pyproject.toml` | `environment.yml` |


---

## Technology Stack

| Layer | Component | Purpose |
|-------|-----------|---------|
| **Frontend** | Streamlit | Chat interface with session memory |
| **API** | FastAPI + uvicorn | Async HTTP endpoints |
| **Orchestration** | LangGraph | ReAct state graph with checkpointing |
| **LLM Integration** | langchain-snowflake | `ChatSnowflake` + `SnowflakeCortexAnalyst` |
| **Reasoning** | claude-3-5-sonnet | Anthropic model via Cortex REST API |
| **Structured Data** | Cortex Analyst API | NLâ†’SQL via semantic model |
| **Unstructured Data** | Cortex Search | FAQs, policies, call transcripts |
| **Validation** | Pydantic v2 | Request/response models |
| **Observability** | OpenTelemetry | GenAI tracing |
| **Deployment** | SPCS | Snowflake Container Services (Distroless) |

---

## Getting Started

### Prerequisites

- Snowflake account with Cortex services enabled
- Python 3.11+ with `uv` package manager
- Key-pair Snowflake authentication configured
- Snow CLI configured

### Quick Start

```bash
# Clone and navigate to project
cd /path/to/healthcare

# Install dependencies
uv sync --group dev

# Run SQL setup scripts
snow sql -c <your_connection_name> --filename scripts/sql/01_setup_db.sql
snow sql -c <your_connection_name> --filename scripts/sql/02_checkpoint_schema.sql
# ... continue with remaining scripts

# Upload semantic model
snow sql -c <your_connection_name> --filename scripts/sql/09_semantic_model.sql
# PUT file to @STAGING.SEMANTIC_MODELS

# Start LangGraph dev server
langgraph dev --port 8123

# Run tests
pytest tests/ -v

# Start FastAPI server locally
uvicorn src.main:app --reload
```

### Environment Variables

Create `.env` file:

```env
# Snowflake Connection
SNOWFLAKE_ACCOUNT=your_account
SNOWFLAKE_USER=your_user
SNOWFLAKE_PRIVATE_KEY_PATH=/path/to/rsa_key.p8
SNOWFLAKE_PRIVATE_KEY_PASSPHRASE=your_passphrase
SNOWFLAKE_DATABASE=HEALTHCARE_DB
SNOWFLAKE_WAREHOUSE=PAYERS_CC_WH
SNOWFLAKE_ROLE=ACCOUNTADMIN

# OpenTelemetry (optional - enables observability)
OTEL_SERVICE_NAME=healthcare-agent
OTEL_EXPORTER_OTLP_ENDPOINT=http://your-otel-collector:4318
OTEL_TRACES_EXPORTER=otlp
```

### SPCS Deployment

```bash
# Build Docker image for linux/amd64 (Distroless)
VERSION=1.0.100
docker buildx build --platform linux/amd64 -t healthcare-agent:$VERSION .

# Tag and push to Snowflake registry
REGISTRY="your-account.registry.snowflakecomputing.com"
docker tag healthcare-agent:$VERSION ${REGISTRY}/healthcare_db/staging/healthcare_images/healthcare-agent:$VERSION
snow spcs image-registry login -c <your_connection_name>
docker push ${REGISTRY}/healthcare_db/staging/healthcare_images/healthcare-agent:$VERSION

# Deploy service
snow sql -c <your_connection_name> --filename scripts/sql/08_spcs_deploy.sql
```

> **langchain-snowflake Patches:**
> 
> We discovered and fixed several bugs in `langchain-snowflake` that affect SPCS deployment and multi-turn conversations. See `patches/README.md` for details.

### Test SPCS Service

```sql
-- Simple query
SELECT STAGING.HEALTHCARE_AGENT_QUERY('How many members do we have?', NULL, 'test_1');

-- Member-specific query
SELECT STAGING.HEALTHCARE_AGENT_QUERY('Tell me about member 786924904', '786924904', 'test_2');

-- Knowledge search
SELECT STAGING.HEALTHCARE_AGENT_QUERY('What is the policy for prescription coverage?', NULL, 'test_3');
```

---

## References

### Original Lab Resources

- **Snowflake QuickStart Guide**: [AI Agent for Health Payers Contact Center](https://quickstarts.snowflake.com/guide/ai_agent_health_payers_cc/index.html)
- **Video Walkthrough**: [YouTube - Healthcare AI Agent Demo](https://youtu.be/UXge7Vv8uSg?si=aWw2GcnCfWRMVzUE)

### Core Technologies

- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)
- [langchain-snowflake](https://github.com/langchain-ai/langchain-snowflake) - Official Snowflake LangChain integration
- [Snowflake Cortex Analyst](https://docs.snowflake.com/en/user-guide/snowflake-cortex/cortex-analyst)
- [Snowflake Cortex Search](https://docs.snowflake.com/en/user-guide/snowflake-cortex/cortex-search)
- [Snowflake Container Services (SPCS)](https://docs.snowflake.com/en/developer-guide/snowpark-container-services/overview)

### Observability

- [OpenTelemetry GenAI Semantic Conventions](https://opentelemetry.io/docs/specs/semconv/gen-ai/)
- [OpenTelemetry Python](https://opentelemetry.io/docs/languages/python/)

---

## License

MIT License - See LICENSE file for details.
